{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4bbb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ad75a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"/home/ryler/Datasets/Mcdonalds-Review-Text-Classification/McDonald_s_Reviews.csv\", encoding=\"latin1\")\n",
    "df = pd.read_csv(\"/home/rynutty/Documents/DataSets/Mcdonalds-Reviews/McDonald_s_Reviews.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e89950f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>store_name</th>\n",
       "      <th>category</th>\n",
       "      <th>store_address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Fast food restaurant</td>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>3 months ago</td>\n",
       "      <td>Why does it look like someone spit on my food?...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Fast food restaurant</td>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>It'd McDonalds. It is what it is as far as the...</td>\n",
       "      <td>4 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Fast food restaurant</td>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Made a mobile order got to the speaker and che...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Fast food restaurant</td>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Fast food restaurant</td>\n",
       "      <td>13749 US-183 Hwy, Austin, TX 78750, United States</td>\n",
       "      <td>30.460718</td>\n",
       "      <td>-97.792874</td>\n",
       "      <td>1,240</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>I repeat my order 3 times in the drive thru, a...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewer_id  store_name              category  \\\n",
       "0            1  McDonald's  Fast food restaurant   \n",
       "1            2  McDonald's  Fast food restaurant   \n",
       "2            3  McDonald's  Fast food restaurant   \n",
       "3            4  McDonald's  Fast food restaurant   \n",
       "4            5  McDonald's  Fast food restaurant   \n",
       "\n",
       "                                       store_address  latitude   longitude  \\\n",
       "0  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "1  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "2  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "3  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "4  13749 US-183 Hwy, Austin, TX 78750, United States  30.460718 -97.792874   \n",
       "\n",
       "  rating_count   review_time  \\\n",
       "0        1,240  3 months ago   \n",
       "1        1,240    5 days ago   \n",
       "2        1,240    5 days ago   \n",
       "3        1,240   a month ago   \n",
       "4        1,240  2 months ago   \n",
       "\n",
       "                                              review   rating  \n",
       "0  Why does it look like someone spit on my food?...   1 star  \n",
       "1  It'd McDonalds. It is what it is as far as the...  4 stars  \n",
       "2  Made a mobile order got to the speaker and che...   1 star  \n",
       "3  My mc. Crispy chicken sandwich was ï¿½ï¿½ï¿½ï¿...  5 stars  \n",
       "4  I repeat my order 3 times in the drive thru, a...   1 star  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2dc8696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33396, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f2cc6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ratings(ratings):\n",
    "    ratings = [int(rate[0]) for rate in ratings]\n",
    "    cleaned_ratings = []\n",
    "\n",
    "    for rating in ratings:\n",
    "        if rating >= 4:\n",
    "            cleaned_ratings.append(2)\n",
    "        elif rating == 3:\n",
    "            cleaned_ratings.append(1)\n",
    "        else:\n",
    "            cleaned_ratings.append(0)\n",
    "\n",
    "    return cleaned_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79a18ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cutoff = int(len(df) * 0.8)\n",
    "\n",
    "train = df.iloc[:train_cutoff, :]\n",
    "test = df.iloc[train_cutoff:, :].reset_index(drop=True)\n",
    "\n",
    "x_train = train[\"review\"]\n",
    "y_train = clean_ratings(train[\"rating\"])\n",
    "\n",
    "x_test = test[\"review\"]\n",
    "y_test = clean_ratings(test[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6be47542",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.inference = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.inference(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, num_encoder_blocks):\n",
    "        super().__init__()\n",
    "\n",
    "        blocks = [EncoderBlock(d_model=d_model, num_heads=num_heads) for _ in range(num_encoder_blocks)]\n",
    "        self.inference = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.inference(x)\n",
    "    \n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, dropout=0.2, batch_first=True, device=\"cuda\")\n",
    "        self.mlp = MLP(in_features=d_model, out_features=d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        identity = x\n",
    "        x, attention_weights = self.mha(x, x, x)\n",
    "        x = x + identity\n",
    "        x = self.layer_norm(x)\n",
    "        identity = x\n",
    "        x = self.mlp(x)\n",
    "        x = x + identity\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SequenceClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "            \n",
    "        self.encoder = Encoder(d_model=768, num_heads=12, num_encoder_blocks=2)\n",
    "        self.head = nn.Linear(in_features=768, out_features=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.head(x)\n",
    "        \n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5142715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        self.model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def __call__(self, sentences: str):\n",
    "\n",
    "        if isinstance(sentences, torch.Tensor):\n",
    "            sentences = list(sentences)\n",
    "            \n",
    "        input_ids = self.tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
    "        embeddings = self.model.embeddings(input_ids)\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0a87e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "\n",
    "    def __init__(self, reviews, ratings):\n",
    "        super().__init__()\n",
    "\n",
    "        self.reviews = reviews\n",
    "        self.ratings = ratings\n",
    "        self.embedder = Embedder()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.reviews[idx], self.ratings[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8eab83e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mSequenceClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m optimizer = torch.optim.Adam(params=model.parameters(), lr=\u001b[32m0.001\u001b[39m, weight_decay=\u001b[32m0.001\u001b[39m)\n\u001b[32m      3\u001b[39m loss_fn = nn.CrossEntropyLoss()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mSequenceClassifier.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28mself\u001b[39m.encoder = \u001b[43mEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m768\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_encoder_blocks\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mself\u001b[39m.head = nn.Linear(in_features=\u001b[32m768\u001b[39m, out_features=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mEncoder.__init__\u001b[39m\u001b[34m(self, d_model, num_heads, num_encoder_blocks)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, d_model, num_heads, num_encoder_blocks):\n\u001b[32m     18\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     blocks = [\u001b[43mEncoderBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_encoder_blocks)]\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mself\u001b[39m.inference = nn.Sequential(*blocks)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mEncoderBlock.__init__\u001b[39m\u001b[34m(self, d_model, num_heads)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m     32\u001b[39m \u001b[38;5;28mself\u001b[39m.layer_norm = nn.LayerNorm(d_model)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28mself\u001b[39m.mha = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMultiheadAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mself\u001b[39m.mlp = MLP(in_features=d_model, out_features=d_model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ProgrammingProjects/CustomModels/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:1092\u001b[39m, in \u001b[36mMultiheadAttention.__init__\u001b[39m\u001b[34m(self, embed_dim, num_heads, dropout, bias, add_bias_kv, add_zero_attn, kdim, vdim, batch_first, device, dtype)\u001b[39m\n\u001b[32m   1089\u001b[39m     \u001b[38;5;28mself\u001b[39m.register_parameter(\u001b[33m\"\u001b[39m\u001b[33min_proj_weight\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1091\u001b[39m     \u001b[38;5;28mself\u001b[39m.in_proj_weight = Parameter(\n\u001b[32m-> \u001b[39m\u001b[32m1092\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m     )\n\u001b[32m   1094\u001b[39m     \u001b[38;5;28mself\u001b[39m.register_parameter(\u001b[33m\"\u001b[39m\u001b[33mq_proj_weight\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28mself\u001b[39m.register_parameter(\u001b[33m\"\u001b[39m\u001b[33mk_proj_weight\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ProgrammingProjects/CustomModels/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:372\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m    371\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mLAZY\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    376\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "model = SequenceClassifier().to(\"cuda\")\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fec43ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ReviewDataset(reviews=x_train, ratings=y_train)\n",
    "test_dataset = ReviewDataset(reviews=x_test, ratings=y_test)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8ded2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d50b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 835/835 [01:21<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.03392066523100306, accuracy: 0.583021410390777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:09<00:00, 22.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.03165995234143948, accuracy: 0.6161676646706586\n",
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 835/835 [01:21<00:00, 10.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.02950204860880304, accuracy: 0.6290238059589759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:09<00:00, 23.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.02941211848380323, accuracy: 0.6357784431137724\n",
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 835/835 [01:21<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.028406943240722935, accuracy: 0.6400284473723611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:09<00:00, 22.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.028214855153046683, accuracy: 0.6471556886227545\n",
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 835/835 [01:19<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.027485091306703107, accuracy: 0.6530169187004042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:08<00:00, 23.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.02820904734516572, accuracy: 0.649251497005988\n",
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 835/835 [01:17<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.02712600261892168, accuracy: 0.6563482557269052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:08<00:00, 23.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.0274582736238748, accuracy: 0.6546407185628742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "embedder = Embedder()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(\"Starting Training...\")\n",
    "\n",
    "    running_train_loss = 0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    model.train()\n",
    "    for reviews, ratings in tqdm(train_dataloader):\n",
    "        embeddings = embedder(reviews).to(\"cuda\")\n",
    "        ratings = ratings.to(\"cuda\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(embeddings)\n",
    "\n",
    "        loss = loss_fn(logits, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "        train_total += len(reviews)\n",
    "        prediction = torch.argmax(logits, dim=1)\n",
    "        train_correct += (prediction == ratings).sum().item()\n",
    "\n",
    "    print(f\"Avg loss: {running_train_loss / train_total}, accuracy: {train_correct / train_total}\")\n",
    "\n",
    "    running_eval_loss = 0\n",
    "    eval_total = 0\n",
    "    eval_correct = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for reviews, ratings in tqdm(test_dataloader):\n",
    "            embeddings = embedder(reviews).to(\"cuda\")\n",
    "            ratings = ratings.to(\"cuda\")\n",
    "\n",
    "            logits = model(embeddings)\n",
    "            loss = loss_fn(logits, ratings)\n",
    "\n",
    "            running_eval_loss += loss.item()\n",
    "            eval_total += len(reviews)\n",
    "            predicted = torch.argmax(logits, dim=1)\n",
    "            eval_correct += (predicted == ratings).sum().item()\n",
    "\n",
    "    print(f\"Avg loss: {running_eval_loss / eval_total}, accuracy: {eval_correct / eval_total}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd02db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42202842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
